#summary Simple examples of using the toolkit
#labels Phase-Deploy,examples,Featured

= Simple Java code examples =

This page describes a basic set of demonstration scripts for using the toolkit. The .java files can be found at [http://code.google.com/p/information-dynamics-toolkit/source/browse/#svn%2Ftrunk%2Fdemos%2Fjava%2Finfodynamics%2Fdemos demos/java/infodynamics/demos] in the svn or main distributions. The demos can be compiled and run with the relevant shell scripts in [http://code.google.com/p/information-dynamics-toolkit/source/browse/#svn%2Ftrunk%2Fdemos%2Fjava demos/java] (one for each example, e.g. [http://code.google.com/p/information-dynamics-toolkit/source/browse/#svn%2Ftrunk%2Fdemos%2Fjava%2Fexample1TeBinaryData.sh example1TeBinaryData.sh])
Please note that other more complicated examples are available from the main [Demos] page.

This page contains the following code examples:
  * [#Example_1_-_Transfer_entropy_on_binary_data Example 1 - Transfer entropy on binary data]
  * [#Example_2_-_Transfer_entropy_on_multidimensional_binary_data Example 2 - Transfer entropy on multidimensional binary data]
  * [#Example_3_-_Transfer_entropy_on_continuous_data_using_kernel_est Example 3 - Transfer entropy on continuous data using kernel estimators]
  * [#Example_4_-_Transfer_entropy_on_continuous_data_using_Kraskov_es Example 4 - Transfer entropy on continuous data using Kraskov estimators]
  * [#Example_5_-_Multivariate_transfer_entropy_on_binary_data Example 5 - Multivariate transfer entropy on binary data]
  * [#Example_6_-_Late_binding_Mutual_info_calculator Example 6 - Late binding Mutual info calculator]
  * [#Example_7_-_Ensemble_approach_for_multiple_samples Example 7 - Transfer entropy via an ensemble of samples]
  * [#Example_8_-_Transfer_entropy_on_continuous_data_using_binning Example 8 - Transfer entropy on continuous data using binning]

= Example 1 - Transfer entropy on binary data =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example1TeBinaryData.java Example1TeBinaryData.java] - Simple transfer entropy (TE) calculation on binary data using the discrete TE calculator:

{{{
// Requires the following imports before the class definition:
// import infodynamics.utils.RandomGenerator;
// import infodynamics.measures.discrete.ApparentTransferEntropyCalculator;

int arrayLengths = 100;
RandomGenerator rg = new RandomGenerator();

// Generate some random binary data:
int[] sourceArray = rg.generateRandomInts(arrayLengths, 2);
int[] destArray = new int[arrayLengths];
destArray[0] = 0;
System.arraycopy(sourceArray, 0, destArray, 1, arrayLengths - 1);
int[] sourceArray2 = rg.generateRandomInts(arrayLengths, 2);

// Create a TE calculator and run it:
ApparentTransferEntropyCalculator teCalc=
		new ApparentTransferEntropyCalculator(2, 1);
teCalc.initialise();
teCalc.addObservations(destArray, sourceArray);
double result = teCalc.computeAverageLocalOfObservations();
System.out.printf("For copied source, result should be close to 1 bit : %.3f bits\n", result);
teCalc.initialise();
teCalc.addObservations(destArray, sourceArray2);
double result2 = teCalc.computeAverageLocalOfObservations();
System.out.printf("For random source, result should be close to 0 bits: %.3f bits\n", result2);
}}}


= Example 2 - Transfer entropy on multidimensional binary data =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example2TeMultidimBinaryData.java Example2TeMultidimBinaryData.java] - Simple transfer entropy (TE) calculation on multidimensional binary data using the discrete TE calculator.

This example shows how to handle multidimensional arrays where we pool the observations over all variables with the discrete calculator.

{{{
// Requires the following imports before the class definition:
// import infodynamics.utils.RandomGenerator;
// import infodynamics.measures.discrete.ApparentTransferEntropyCalculator;

int timeSteps = 2;
int variables = 100;
RandomGenerator rg = new RandomGenerator();

// Create many columns in a multidimensional array (2 rows by 100 columns),
//  where the next time step (row 2) copies the value of the column on the left
//  from the previous time step (row 1):
int[][] twoDTimeSeries = new int[timeSteps][];
twoDTimeSeries[0] = rg.generateRandomInts(variables, 2);
twoDTimeSeries[1] = new int[variables];
twoDTimeSeries[1][0] = twoDTimeSeries[0][variables - 1];
System.arraycopy(twoDTimeSeries[0], 0, twoDTimeSeries[1], 1, variables - 1);

// Create a TE calculator and run it:
ApparentTransferEntropyCalculator teCalc=
		new ApparentTransferEntropyCalculator(2, 1);
teCalc.initialise();
// Add observations of transfer across one cell to the right (j=1)
//  per time step:
teCalc.addObservations(twoDTimeSeries, 1);

double result2D = teCalc.computeAverageLocalOfObservations();
System.out.printf("The result should be close to 1 bit here, " +
		"since we are executing copy operations of what is effectively " +
		"a random bit to each cell here: %.3f bits\n", result2D);
}}}

= Example 3 - Transfer entropy on continuous data using kernel estimators =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example3TeContinuousDataKernel.java Example3TeContinuousDataKernel.java] - Simple transfer entropy (TE) calculation on continuous-valued data using the (box) kernel-estimator TE calculator.

{{{
// Requires the following imports before the class definition:
// import infodynamics.utils.RandomGenerator;
// import infodynamics.measures.continuous.kernel.TransferEntropyCalculatorKernel;

// Generate some random normalised data.
int numObservations = 1000;
double covariance = 0.4;

// Create destArray correlated to previous value of sourceArray:
RandomGenerator rg = new RandomGenerator();
double[] sourceArray = rg.generateNormalData(numObservations, 0, 1);
double[] destArray = rg.generateNormalData(numObservations, 0, 1-covariance);
for (int t = 1; t < numObservations; t++) {
	destArray[t] += covariance * sourceArray[t-1];
}
// And an uncorrelated second source
double[] sourceArray2 = rg.generateNormalData(numObservations, 0, 1);

// Create a TE calculator and run it:
TransferEntropyCalculatorKernel teCalc =
		new TransferEntropyCalculatorKernel();
teCalc.setProperty("NORMALISE", "true"); // Normalise the individual variables (default)
teCalc.initialise(1, 0.5); // Use history length 1 (Schreiber k=1), kernel width of 0.5 normalised units
teCalc.setObservations(sourceArray, destArray);
// For copied source, should give something close to 1 bit:
double result = teCalc.computeAverageLocalOfObservations();
System.out.printf("TE result %.4f bits; expected to be close to " +
		"%.4f bits for these correlated Gaussians but biased upwards\n",
		result, Math.log(1.0/(1-Math.pow(covariance,2)))/Math.log(2));

teCalc.initialise(); // Initialise leaving the parameters the same
teCalc.setObservations(sourceArray2, destArray);
// For random source, it should give something close to 0 bits
double result2 = teCalc.computeAverageLocalOfObservations();
System.out.printf("TE result %.4f bits; expected to be close to " +
		"0 bits for uncorrelated Gaussians but will be biased upwards\n",
		result2);

// We can get insight into the bias by examining the null distribution:
EmpiricalMeasurementDistribution nullDist = teCalc.computeSignificance(100);
System.out.printf("Null distribution for unrelated source and destination " +
	"(i.e. the bias) has mean %.4f and standard deviation %.4f\n",
	nullDist.getMeanOfDistribution(), nullDist.getStdOfDistribution());
}}}

= Example 4 - Transfer entropy on continuous data using Kraskov estimators =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example4TeContinuousDataKraskov.java Example4TeContinuousDataKraskov.java] - Simple transfer entropy (TE) calculation on continuous-valued data using the Kraskov-estimator TE calculator.

{{{
// Requires the following imports before the class definition:
// import infodynamics.utils.RandomGenerator;
// import infodynamics.measures.continuous.kraskov.TransferEntropyCalculatorKraskov;

// Generate some random normalised data.
int numObservations = 1000;
double covariance = 0.4;

// Create destArray correlated to previous value of sourceArray:
RandomGenerator rg = new RandomGenerator();
double[] sourceArray = rg.generateNormalData(numObservations, 0, 1);
double[] destArray = rg.generateNormalData(numObservations, 0, 1-covariance);
for (int t = 1; t < numObservations; t++) {
	destArray[t] += covariance * sourceArray[t-1];
}
// And an uncorrelated second source
double[] sourceArray2 = rg.generateNormalData(numObservations, 0, 1);

// Create a TE calculator and run it:
TransferEntropyCalculatorKraskov teCalc =
		new TransferEntropyCalculatorKraskov();
teCalc.setProperty("k", "4"); // Use Kraskov parameter K=4 for 4 nearest neighbours
teCalc.initialise(1); // Use history length 1 (Schreiber k=1)

// Perform calculation with correlated source:
teCalc.setObservations(sourceArray, destArray);
double result = teCalc.computeAverageLocalOfObservations();
// Note that the calculation is a random variable (because the generated
//  data is a set of random variables) - the result will be of the order
//  of what we expect, but not exactly equal to it; in fact, there will
//  be a large variance around it.
System.out.printf("TE result %.4f nats; expected to be close to " +
		"%.4f nats for these correlated Gaussians\n",
		result, Math.log(1.0/(1-Math.pow(covariance,2))));

//  Perform calculation with uncorrelated source:
teCalc.initialise(); // Initialise leaving the parameters the same
teCalc.setObservations(sourceArray2, destArray);
// For random source, it should give something close to 0 bits
double result2 = teCalc.computeAverageLocalOfObservations();
System.out.printf("TE result %.4f nats; expected to be close to " +
		"0 nats for these uncorrelated Gaussians\n", result2);

// We can also compute the local TE values for the time-series samples here:
//  (See more about utility of local TE in the CA demos)
double[] localTE = teCalc.computeLocalOfPreviousObservations();

}}}

= Example 5 - Multivariate transfer entropy on binary data =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example5TeBinaryMultivarTransfer.java Example5TeBinaryMultivarTransfer.java] - Multivariate transfer entropy (TE) calculation on binary data using the discrete TE calculator.

{{{
// Requires the following imports before the class definition:
// import infodynamics.utils.MatrixUtils;
// import infodynamics.utils.RandomGenerator;
// import infodynamics.measures.discrete.ApparentTransferEntropyCalculator;

// Generate some random binary data.
int timeSeriesLength = 100;
RandomGenerator rg = new RandomGenerator();
int[][] sourceArray = rg.generateRandomInts(timeSeriesLength, 2, 2);
int[][] sourceArray2 = rg.generateRandomInts(timeSeriesLength, 2, 2);
// Destination variable takes a copy of the first bit of the 
//  previous source value in bit 0,
//  and an XOR of the two previous bits of the source in bit 1:
int[][] destArray = new int[timeSeriesLength][2];
for (int r = 1; r < timeSeriesLength; r++) {
	// This is a bitwise XOR, but is fine for our purposes
	//  with binary data:
	destArray[r][0] = sourceArray[r - 1][0];
	destArray[r][1]	= sourceArray[r - 1][0] ^ sourceArray[r - 1][1];
}

// Create a TE calculator and run it.
// Need to represent 4-state variables for the joint destination variable
ApparentTransferEntropyCalculator teCalc=
		new ApparentTransferEntropyCalculator(4, 1);
teCalc.initialise();

// We need to construct the joint values of the dest and source before we pass them in:
teCalc.addObservations(MatrixUtils.computeCombinedValues(destArray, 2),
		MatrixUtils.computeCombinedValues(sourceArray, 2));

double result = teCalc.computeAverageLocalOfObservations();
System.out.printf("For source which the 2 bits are determined from, " +
		"result should be close to 2 bits : %.3f\n", result);

// Check random source:
teCalc.initialise();
teCalc.addObservations(MatrixUtils.computeCombinedValues(destArray, 2),
		MatrixUtils.computeCombinedValues(sourceArray2, 2));
double result2 = teCalc.computeAverageLocalOfObservations();
System.out.printf("For random source, result should be close to 0 bits " +
		"in theory: %.3f\n", result2);

System.out.printf("The result for random source is inflated towards 0.3 " +
		" due to finite observation length (%d). One can verify that the " +
		"answer is consistent with that from a random source by checking: " +
		"teCalc.computeSignificance(1000); ans.pValue\n",
		teCalc.getNumObservations());
}}}

= Example 6 - Late binding Mutual info calculator =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example6LateBindingMutualInfo.java Example6LateBindingMutualInfo.java] - This class is used to demonstrate the manner in which a user can code to the interfaces defined in `infodynamics.measures.continuous`, and dynamically alter the instantiated class at runtime. We demonstrate this using a multivariate mutual information calculation. The properties file (supplied on command line) to specify the name of the dynamically instantiated class is available in the distribution at [http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/example6LateBindingMutualInfo.props demos/java/example6LateBindingMutualInfo.props].

This example also demonstrates how to read simple files of arrays of data with the toolkit, as well as how to dynamically load properties from a java properties file. 

{{{
// Requires the following imports before the class definition:
// import infodynamics.measures.continuous.MutualInfoCalculatorMultiVariate;
// import infodynamics.utils.ArrayFileReader;
// import infodynamics.utils.MatrixUtils;
// import infodynamics.utils.ParsedProperties;

/**
 * @param args One command line argument taken, specifying location of 
 *  the properties file. This should be example6LateBindingMutualInfo.props
 *  in the demos/java directory.
 */
public static void main(String[] args) throws Exception {
	
	// 0. Preliminaries (reading in the dynamic properties and the data):
	//  a. Read in the properties file defined as the first
	//     command line argument:
	ParsedProperties props = new ParsedProperties(args[0]);
	//  b. Read in the data file, whose filename is defined in the
	//     property "datafile" in our properties file:
	ArrayFileReader afr = new ArrayFileReader(props.getStringProperty("datafile"));
	double[][] data = afr.getDouble2DMatrix();
	//  c. Pull out the columns from the data set which 
	//     correspond to each of variable 1 and 2: 
	int[] variable1Columns = props.getIntArrayProperty("variable1Columns");
	int[] variable2Columns = props.getIntArrayProperty("variable2Columns");
	double[][] variable1 = MatrixUtils.selectColumns(data, variable1Columns);
	double[][] variable2 = MatrixUtils.selectColumns(data, variable2Columns);
	
	// 1. Create a reference for our calculator as
	//  an object implementing the interface type:
	MutualInfoCalculatorMultiVariate miCalc;
	
	// 2. Define the name of the class to be instantiated here:
	String implementingClass = props.getStringProperty("implementingClass");
	
	// 3. Dynamically instantiate an object of the given class:
	//  Part 1: Class.forName(implementingClass) grabs a reference to
	//   the class named by implementingClass.
	//  Part 2: .newInstance() creates an object instance of that class.
	//  Part 3: (MutualInfoCalculatorMultiVariate) casts the return
	//   object into an instance of our generic interface type.
	miCalc = (MutualInfoCalculatorMultiVariate)
			Class.forName(implementingClass).newInstance();
	
	// 4. Start using our MI calculator, paying attention to only
	//  call common methods defined in the interface type, not methods
	//  only defined in a given implementation class.
	// a. Initialise the calculator to use the required number of
	//   dimensions for each variable:
	miCalc.initialise(variable1Columns.length, variable2Columns.length);
	// b. Supply the observations to compute the PDFs from:
	miCalc.setObservations(variable1, variable2);
	// c. Make the MI calculation:
	double miValue = miCalc.computeAverageLocalOfObservations();
	
	System.out.printf("MI calculator %s computed the joint MI as %.5f\n",
			implementingClass, miValue);
}
}}}


= Example 7 - Ensemble approach for multiple samples =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example7EnsembleMethodTeContinuousDataKraskov.java Example7EnsembleMethodTeContinuousDataKraskov.java] - This class is used to demonstrate the manner in which a user supplies an ensemble of samples from multiple time series.

{{{
// Requires the following imports before the class definition:
// import infodynamics.measures.continuous.kraskov.TransferEntropyCalculatorKraskov;
// import infodynamics.utils.RandomGenerator;

// Prepare to generate some random normalised data.
int numObservations = 1000;
double covariance = 0.4;
RandomGenerator rg = new RandomGenerator();

// Create a TE calculator and run it:
TransferEntropyCalculatorKraskov teCalc =
		new TransferEntropyCalculatorKraskov();
teCalc.setProperty("k", "4"); // Use Kraskov parameter K=4 for 4 nearest neighbours
teCalc.initialise(1); // Use history length 1 (Schreiber k=1)
teCalc.startAddObservations();

for (int trial = 0; trial < 10; trial++) {

	// Create a new trial, with destArray correlated to
	//  previous value of sourceArray:
	double[] sourceArray = rg.generateNormalData(numObservations, 0, 1);
	double[] destArray = rg.generateNormalData(numObservations, 0, 1-covariance);
	for (int t = 1; t < numObservations; t++) {
		destArray[t] += covariance * sourceArray[t-1];
	}
	
	// Add observations for this trial:
	System.out.printf("Adding samples from trial %d ...\n", trial);
	teCalc.addObservations(sourceArray, destArray);
}

// We've finished adding trials:
System.out.println("Finished adding trials");
teCalc.finaliseAddObservations();

// Compute the result:
System.out.println("Computing TE ...");
double result = teCalc.computeAverageLocalOfObservations();
// Note that the calculation is a random variable (because the generated
//  data is a set of random variables) - the result will be of the order
//  of what we expect, but not exactly equal to it; in fact, there will
//  be some variance around it (smaller than example 4 since we have more samples).
System.out.printf("TE result %.4f nats; expected to be close to " +
		"%.4f nats for these correlated Gaussians\n",
		result, Math.log(1.0/(1-Math.pow(covariance,2))));
}}}




= Example 8 - Transfer entropy on continuous data using binning =

[http://code.google.com/p/information-dynamics-toolkit/source/browse/trunk/demos/java/infodynamics/demos/Example8TeContinuousDataByBinning.java Example8TeContinuousDataByBinning.java] - Simple transfer entropy (TE) calculation on continuous-valued data by binning the continuous data to discrete, then using a discrete TE calculator.

{{{
// Requires the following imports before the class definition:
// import infodynamics.measures.discrete.ApparentTransferEntropyCalculator;
// import infodynamics.utils.MatrixUtils;
// import infodynamics.utils.RandomGenerator;

// Prepare to generate some random normalised data.
int numObservations = 1000;
double covariance = 0.4;
int numDiscreteLevels = 4;

// Create destArray correlated to previous value of sourceArray:
RandomGenerator rg = new RandomGenerator();
double[] sourceArray = rg.generateNormalData(numObservations, 0, 1);
double[] destArray = rg.generateNormalData(numObservations, 0, 1-covariance);
for (int t = 1; t < numObservations; t++) {
	destArray[t] += covariance * sourceArray[t-1];
}

// Discretize or bin the data -- one could also call:
//  MatrixUtils.discretiseMaxEntropy for a maximum entropy binning
int[] binnedSource = MatrixUtils.discretise(sourceArray, numDiscreteLevels);
int[] binnedDest = MatrixUtils.discretise(destArray, numDiscreteLevels);

// Create a TE calculator and run it:
ApparentTransferEntropyCalculator teCalc=
new ApparentTransferEntropyCalculator(numDiscreteLevels, 1);
teCalc.initialise();
teCalc.addObservations(binnedDest, binnedSource);
double result = teCalc.computeAverageLocalOfObservations();
// Calculation will be heavily biased because of the binning,
//  and the small number of samples
System.out.printf("TE result %.4f bits; expected to be close to " +
		"%.4f bits for these correlated Gaussians\n",
		result, Math.log(1.0/(1-Math.pow(covariance,2)))/Math.log(2));
}}}